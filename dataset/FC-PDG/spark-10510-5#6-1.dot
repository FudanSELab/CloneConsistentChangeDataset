digraph {
15 [style = filled, label = "main['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
16 [style = filled, label = "Dataset<Row> test = sqlContext.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@20@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
2 [style = filled, label = "HashingTF hashingTF = new HashingTF().setNumFeatures(1000).setInputCol(tokenizer.getOutputCol()).setOutputCol(\"features\")@@@8@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
14 [style = filled, label = "SQLContext sqlContext = new SQLContext(sc)@@@5@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
22 [style = filled, label = "Dataset<Row> training = sqlContext.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0),new JavaLabeledDocument(4L,\"b spark who\",1.0),new JavaLabeledDocument(5L,\"g d a y\",0.0),new JavaLabeledDocument(6L,\"spark fly\",1.0),new JavaLabeledDocument(7L,\"was mapreduce\",0.0),new JavaLabeledDocument(8L,\"e spark program\",1.0),new JavaLabeledDocument(9L,\"a e c l\",0.0),new JavaLabeledDocument(10L,\"spark compile\",1.0),new JavaLabeledDocument(11L,\"hadoop software\",0.0)),)@@@6@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
24 [style = filled, label = "CrossValidatorModel cvModel = cv.fit(training)@@@19@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
4 [style = filled, label = "PipelineModel model = pipeline.fit(training)@@@13@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
7 [style = filled, label = "Pipeline pipeline = new Pipeline().setStages(new PipelineStage((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a629b6)@@@10@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
17 [style = filled, label = "SparkConf conf = new SparkConf().setAppName(\"JavaModelSelectionViaCrossValidationExample\")@@@3@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
6 [style = filled, label = "Dataset<Row> test = sqlContext.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@14@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
0 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@17@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
11 [style = filled, label = "Dataset<Row> training = sqlContext.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0)),)@@@6@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
5 [style = filled, label = "SparkConf conf = new SparkConf().setAppName(\"JavaPipelineExample\")@@@3@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
1 [style = filled, label = "main['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
21 [style = filled, label = "ParamMap(( paramGrid = new ParamGridBuilder().addGrid(hashingTF.numFeatures(),new int((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a629c9).addGrid(lr.regParam(),new double((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a629d3).build()@@@13@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
19 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@23@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
23 [style = filled, label = "sc.stop()@@@25@@@['0', '0', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB3BBB"];
10 [style = filled, label = "SparkContext sc = new SparkContext(conf)@@@4@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
18 [style = filled, label = "Dataset<Row> predictions = cvModel.transform(test)@@@21@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
20 [style = filled, label = "CrossValidator cv = new CrossValidator().setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator()).setEstimatorParamMaps(paramGrid).setNumFolds(2)@@@18@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
12 [style = filled, label = "Tokenizer tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")@@@7@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
13 [style = filled, label = "LogisticRegression lr = new LogisticRegression().setMaxIter(10).setRegParam(0.01)@@@9@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
8 [style = filled, label = "sc.stop()@@@19@@@['1', '1', '0']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB1BBB"];
25 [style = filled, label = "main['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
9 [style = filled, label = "Dataset<Row> predictions = model.transform(test)@@@15@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
3 [style = filled, label = "String(( args@@@2@@@['1', '1', '1']", fillcolor = tomato, shape = box image = "AAA0AAABBB1BBB"];
1->5 [style = bold, label=""];
17->10 [style = bold, label=""];
5->10 [style = bold, label=""];
16->18 [style = bold, label=""];
5->10 [style = solid, label="conf"];
9->0 [style = bold, label=""];
10->14 [style = bold, label=""];
4->6 [style = bold, label=""];
9->18 [style = dashed, label="0"];
14->22 [style = bold, label=""];
18->19 [style = bold, label=""];
11->22 [style = dashed, label="0"];
2->7 [style = solid, label="hashingTF"];
13->7 [style = solid, label="lr"];
11->12 [style = bold, label=""];
7->4 [style = bold, label=""];
22->24 [style = solid, label="training"];
25->17 [style = bold, label=""];
15->5 [style = bold, label=""];
2->13 [style = bold, label=""];
1->3 [style = dotted, label="true"];
15->3 [style = dotted, label="true"];
12->7 [style = solid, label="tokenizer"];
24->16 [style = bold, label=""];
12->2 [style = bold, label=""];
16->18 [style = solid, label="test"];
21->20 [style = bold, label=""];
5->17 [style = dashed, label="0"];
17->10 [style = solid, label="conf"];
13->7 [style = bold, label=""];
22->12 [style = bold, label=""];
19->23 [style = bold, label=""];
6->9 [style = solid, label="test"];
0->8 [style = bold, label=""];
10->14 [style = solid, label="sc"];
7->21 [style = bold, label=""];
25->3 [style = dotted, label="true"];
11->4 [style = solid, label="training"];
6->9 [style = bold, label=""];
20->24 [style = bold, label=""];
14->11 [style = bold, label=""];
}
