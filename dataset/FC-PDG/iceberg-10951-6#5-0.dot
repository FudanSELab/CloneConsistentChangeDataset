digraph {
19 [style = filled, label = "testImportWithNameMapping['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
0 [style = filled, label = "File stagingDir = temp.newFolder(\"staging-dir\")@@@9@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
9 [style = filled, label = "SparkTableUtil.importSparkTable(spark,source,table,stagingDir.toString())@@@10@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
5 [style = filled, label = "TableIdentifier source = new TableIdentifier(\"original_table\")@@@6@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
6 [style = filled, label = "Assert.assertEquals(expected,actual)@@@13@@@['1', '1', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB1BBB"];
7 [style = filled, label = "spark.table(qualifiedTableName).write().mode(\"overwrite\").format(\"parquet\").saveAsTable(\"original_table\")@@@3@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
10 [style = filled, label = "Schema filteredSchema = new Schema(optional(1,\"data\",Types.StringType.get()))@@@4@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
11 [style = filled, label = "TableIdentifier source = new TableIdentifier(\"original_table\")@@@7@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
14 [style = filled, label = "Assume.assumeTrue(\"Applies only to parquet format.\",FileFormat.PARQUET == format)@@@3@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
12 [style = filled, label = "Assert.assertEquals(expected,actual)@@@14@@@['0', '1', '0']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB2BBB"];
18 [style = filled, label = "List<String> actual = spark.read().format(\"iceberg\").load(DB_NAME + \".target_table\").select(\"data\").sort(\"data\").filter(\"data >= 'b'\").as(Encoders.STRING()).collectAsList()@@@11@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
3 [style = filled, label = "List<String> expected = Lists.newArrayList(\"b\",\"c\")@@@12@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
15 [style = filled, label = "testImportWithNameMappingForVectorizedParquetReader['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
4 [style = filled, label = "NameMapping nameMapping = MappingUtil.create(filteredSchema)@@@5@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
16 [style = filled, label = "Table table = catalog.createTable(org.apache.iceberg.catalog.TableIdentifier.of(DB_NAME,\"target_table\"),filteredSchema,SparkSchemaUtil.specForTable(spark,\"original_table\"))@@@7@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
2 [style = filled, label = "Table table = catalog.createTable(org.apache.iceberg.catalog.TableIdentifier.of(DB_NAME,\"target_table_for_vectorization\"),filteredSchema,SparkSchemaUtil.specForTable(spark,\"original_table\"))@@@8@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
17 [style = filled, label = "table.updateProperties().set(DEFAULT_NAME_MAPPING,NameMappingParser.toJson(nameMapping)).commit()@@@8@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
8 [style = filled, label = "SparkTableUtil.importSparkTable(spark,source,table,stagingDir.toString())@@@11@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
13 [style = filled, label = "spark.table(QUALIFIED_TABLE_NAME).write().mode(\"overwrite\").format(format.toString()).saveAsTable(\"original_table\")@@@4@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA1AAABBB2BBB"];
1 [style = filled, label = "testImportWithNameMappingForVectorizedParquetReader['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
9->18 [style = bold, label=""];
18->3 [style = bold, label=""];
2->8 [style = solid, label="table"];
4->5 [style = solid, label="filteredSchema"];
13->4 [style = bold, label=""];
8->18 [style = dashed, label="0"];
18->6 [style = solid, label="actual"];
7->10 [style = bold, label=""];
11->9 [style = solid, label="table"];
2->17 [style = dashed, label="0"];
4->5 [style = bold, label=""];
16->9 [style = solid, label="table"];
0->9 [style = bold, label=""];
14->13 [style = bold, label=""];
5->9 [style = solid, label="source"];
11->2 [style = bold, label=""];
8->3 [style = bold, label=""];
3->6 [style = bold, label=""];
3->6 [style = solid, label="expected"];
6->12 [style = solid, label="expected"];
3->12 [style = solid, label="actual"];
5->11 [style = bold, label=""];
10->4 [style = bold, label=""];
15->14 [style = bold, label=""];
11->16 [style = dashed, label="0"];
4->2 [style = solid, label="filteredSchema"];
11->8 [style = solid, label="source"];
6->12 [style = bold, label=""];
10->4 [style = solid, label="filteredSchema"];
10->11 [style = solid, label="filteredSchema"];
2->0 [style = bold, label=""];
16->17 [style = bold, label=""];
8->6 [style = solid, label="actual"];
9->8 [style = bold, label=""];
1->7 [style = bold, label=""];
19->7 [style = bold, label=""];
10->16 [style = solid, label="filteredSchema"];
5->16 [style = bold, label=""];
17->0 [style = bold, label=""];
}
