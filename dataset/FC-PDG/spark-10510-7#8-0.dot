digraph {
4 [style = filled, label = "Dataset<Row> predictions = model.transform(test)@@@13@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
5 [style = filled, label = "SQLContext sqlContext = new SQLContext(sc)@@@5@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
19 [style = filled, label = "Dataset<Row> test = spark.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@12@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
14 [style = filled, label = "SparkConf conf = new SparkConf().setAppName(\"JavaPipelineExample\")@@@3@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
22 [style = filled, label = "Dataset<Row> training = sqlContext.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0),new JavaLabeledDocument(4L,\"b spark who\",1.0),new JavaLabeledDocument(5L,\"g d a y\",0.0),new JavaLabeledDocument(6L,\"spark fly\",1.0),new JavaLabeledDocument(7L,\"was mapreduce\",0.0),new JavaLabeledDocument(8L,\"e spark program\",1.0),new JavaLabeledDocument(9L,\"a e c l\",0.0),new JavaLabeledDocument(10L,\"spark compile\",1.0),new JavaLabeledDocument(11L,\"hadoop software\",0.0)),)@@@6@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
6 [style = filled, label = "Dataset<Row> training = sqlContext.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0)),)@@@6@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
1 [style = filled, label = "sc.stop()@@@19@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
11 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@15@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
23 [style = filled, label = "CrossValidator cv = new CrossValidator().setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator()).setEstimatorParamMaps(paramGrid).setNumFolds(2)@@@18@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
31 [style = filled, label = "ParamMap(( paramGrid = new ParamGridBuilder().addGrid(hashingTF.numFeatures(),new int((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78a74).addGrid(lr.regParam(),new double((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78a7e).build()@@@13@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
16 [style = filled, label = "main['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
30 [style = filled, label = "Dataset<Row> predictions = cvModel.transform(test)@@@21@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
10 [style = filled, label = "spark.stop()@@@17@@@['1', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
21 [style = filled, label = "SparkSession spark = SparkSession.builder().appName(\"JavaPipelineExample\").getOrCreate()@@@3@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
7 [style = filled, label = "Dataset<Row> test = sqlContext.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@14@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
13 [style = filled, label = "SparkContext sc = new SparkContext(conf)@@@4@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
27 [style = filled, label = "main['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
24 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@23@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
28 [style = filled, label = "sc.stop()@@@25@@@['0', '0', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB3BBB"];
0 [style = filled, label = "String(( args@@@2@@@['1', '1', '1']", fillcolor = tomato, shape = box image = "AAA0AAABBB1BBB"];
12 [style = filled, label = "HashingTF hashingTF = new HashingTF().setNumFeatures(1000).setInputCol(tokenizer.getOutputCol()).setOutputCol(\"features\")@@@8@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
17 [style = filled, label = "Dataset<Row> training = spark.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0)),)@@@4@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
29 [style = filled, label = "SparkConf conf = new SparkConf().setAppName(\"JavaModelSelectionViaCrossValidationExample\")@@@3@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
3 [style = filled, label = "main['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
20 [style = filled, label = "HashingTF hashingTF = new HashingTF().setNumFeatures(1000).setInputCol(tokenizer.getOutputCol()).setOutputCol(\"features\")@@@6@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
9 [style = filled, label = "LogisticRegression lr = new LogisticRegression().setMaxIter(10).setRegParam(0.01)@@@9@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
26 [style = filled, label = "CrossValidatorModel cvModel = cv.fit(training)@@@19@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
15 [style = filled, label = "Tokenizer tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")@@@5@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
8 [style = filled, label = "Tokenizer tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")@@@7@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
2 [style = filled, label = "Pipeline pipeline = new Pipeline().setStages(new PipelineStage((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78a61)@@@10@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
18 [style = filled, label = "PipelineModel model = pipeline.fit(training)@@@11@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
25 [style = filled, label = "Dataset<Row> test = sqlContext.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@20@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
22->26 [style = solid, label="training"];
12->2 [style = solid, label="hashingTF"];
13->5 [style = solid, label="sc"];
30->24 [style = bold, label=""];
24->28 [style = bold, label=""];
15->12 [style = solid, label="tokenizer"];
7->11 [style = bold, label=""];
31->23 [style = bold, label=""];
6->4 [style = solid, label="training"];
9->2 [style = bold, label=""];
25->30 [style = bold, label=""];
26->25 [style = bold, label=""];
3->14 [style = bold, label=""];
18->19 [style = bold, label=""];
17->18 [style = solid, label="training"];
23->26 [style = bold, label=""];
14->13 [style = solid, label="conf"];
1->10 [style = dashed, label="0"];
8->12 [style = solid, label="lr"];
12->9 [style = bold, label=""];
9->2 [style = solid, label="lr"];
2->4 [style = bold, label=""];
6->22 [style = dashed, label="0"];
4->7 [style = bold, label=""];
22->8 [style = bold, label=""];
20->8 [style = bold, label=""];
5->6 [style = bold, label=""];
16->0 [style = dotted, label="true"];
27->0 [style = dotted, label="true"];
7->19 [style = dashed, label="0"];
11->10 [style = bold, label=""];
15->20 [style = bold, label=""];
16->21 [style = bold, label=""];
6->8 [style = bold, label=""];
12->18 [style = bold, label=""];
20->12 [style = solid, label="hashingTF"];
17->15 [style = bold, label=""];
13->5 [style = bold, label=""];
3->0 [style = dotted, label="true"];
14->21 [style = dashed, label="0"];
7->11 [style = solid, label="test"];
25->30 [style = solid, label="test"];
19->4 [style = bold, label=""];
14->13 [style = bold, label=""];
27->29 [style = bold, label=""];
29->13 [style = solid, label="conf"];
11->30 [style = dashed, label="0"];
4->11 [style = bold, label=""];
10->1 [style = bold, label=""];
14->29 [style = dashed, label="0"];
5->22 [style = bold, label=""];
21->17 [style = bold, label=""];
8->12 [style = bold, label=""];
19->4 [style = solid, label="test"];
8->2 [style = solid, label="tokenizer"];
2->31 [style = bold, label=""];
29->13 [style = bold, label=""];
}
