digraph {
6 [style = filled, label = "updateHiveSyncConfig(writer)@@@4@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
3 [style = filled, label = "DataStreamWriter<Row> writer = streamingInput.writeStream().format(\"org.apache.hudi\").option(\"hoodie.insert.shuffle.parallelism\",\"2\").option(\"hoodie.upsert.shuffle.parallelism\",\"2\").option(\"hoodie.delete.shuffle.parallelism\",\"2\").option(DataSourceWriteOptions.OPERATION().key(),operationType).option(DataSourceWriteOptions.TABLE_TYPE().key(),tableType).option(DataSourceWriteOptions.RECORDKEY_FIELD().key(),\"_row_key\").option(DataSourceWriteOptions.PARTITIONPATH_FIELD().key(),\"partition\").option(DataSourceWriteOptions.PRECOMBINE_FIELD().key(),\"timestamp\").option(HoodieCompactionConfig.INLINE_COMPACT_NUM_DELTA_COMMITS_PROP.key(),\"1\").option(DataSourceWriteOptions.ASYNC_COMPACT_ENABLE().key(),\"true\").option(DataSourceWriteOptions.ASYNC_CLUSTERING_ENABLE().key(),\"true\").option(HoodieWriteConfig.TABLE_NAME.key(),tableName).option(\"checkpointLocation\",checkpointLocation).outputMode(OutputMode.Append())@@@3@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
4 [style = filled, label = "StreamingQuery query = writer.trigger(Trigger.ProcessingTime(500)).start(tablePath)@@@5@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
21 [style = filled, label = "updateHiveSyncConfig(writer)@@@10@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
8 [style = filled, label = "DataStreamWriter<Row> writer = streamingInput.writeStream().format(\"org.apache.hudi\").option(\"hoodie.insert.shuffle.parallelism\",\"2\").option(\"hoodie.upsert.shuffle.parallelism\",\"2\").option(\"hoodie.delete.shuffle.parallelism\",\"2\").option(DataSourceWriteOptions.OPERATION().key(),operationType).option(DataSourceWriteOptions.TABLE_TYPE().key(),tableType).option(DataSourceWriteOptions.RECORDKEY_FIELD().key(),\"_row_key\").option(DataSourceWriteOptions.PARTITIONPATH_FIELD().key(),\"partition\").option(DataSourceWriteOptions.PRECOMBINE_FIELD().key(),\"timestamp\").option(HoodieCompactionConfig.INLINE_COMPACT_NUM_DELTA_COMMITS.key(),\"1\").option(DataSourceWriteOptions.ASYNC_COMPACT_ENABLE().key(),\"true\").option(DataSourceWriteOptions.ASYNC_CLUSTERING_ENABLE().key(),\"true\").option(HoodieWriteConfig.TABLE_NAME.key(),tableName).option(\"checkpointLocation\",checkpointLocation).outputMode(OutputMode.Append())@@@3@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
18 [style = filled, label = "JavaSparkContext jssc = new JavaSparkContext(spark.sparkContext())@@@4@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
20 [style = filled, label = "List<HoodieRecord> recordsSoFar = new ArrayList<>(dataGen.generateInserts(instantTime,100))@@@6@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
19 [style = filled, label = "writer.save(tablePath)@@@11@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
11 [style = filled, label = "String operationType@@@2@@@['0', '1', '0']", fillcolor = tomato, shape = box image = "AAA0AAABBB2BBB"];
25 [style = filled, label = "String instantTime = HoodieActiveTimeline.createNewInstantTime()@@@5@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
17 [style = filled, label = "SparkSession spark@@@2@@@['0', '0', '1']", fillcolor = tomato, shape = box image = "AAA0AAABBB3BBB"];
13 [style = filled, label = "DataFrameWriter<Row> writer = inputDF1.write().format(\"org.apache.hudi\").option(\"hoodie.insert.shuffle.parallelism\",\"2\").option(\"hoodie.upsert.shuffle.parallelism\",\"2\").option(DataSourceWriteOptions.TABLE_TYPE().key(),tableType).option(DataSourceWriteOptions.OPERATION().key(),DataSourceWriteOptions.INSERT_OPERATION_OPT_VAL()).option(DataSourceWriteOptions.RECORDKEY_FIELD().key(),\"_row_key\").option(DataSourceWriteOptions.PARTITIONPATH_FIELD().key(),\"partition\").option(DataSourceWriteOptions.PRECOMBINE_FIELD().key(),\"timestamp\").option(HoodieWriteConfig.TABLE_NAME.key(),tableName).option(DataSourceWriteOptions.KEYGENERATOR_CLASS().key(),nonPartitionedTable? .getCanonicalName(): .getCanonicalName()).mode(commitType)@@@9@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
9 [style = filled, label = "stream['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
2 [style = filled, label = "String checkpointLocation@@@2@@@['1', '0', '0']", fillcolor = tomato, shape = box image = "AAA0AAABBB1BBB"];
14 [style = filled, label = "LOG.info(\"Commit at instant time :\" + commitInstantTime1)@@@14@@@['0', '0', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB3BBB"];
10 [style = filled, label = "Dataset<Row> streamingInput@@@2@@@['0', '1', '0']", fillcolor = tomato, shape = box image = "AAA0AAABBB2BBB"];
7 [style = filled, label = "String checkpointLocation@@@2@@@['1', '1', '0']", fillcolor = tomato, shape = box image = "AAA0AAABBB1BBB"];
22 [style = filled, label = "Dataset<Row> inputDF1 = spark.read().json(jssc.parallelize(records1,2))@@@8@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
23 [style = filled, label = "insert['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
15 [style = filled, label = "HoodieTestDataGenerator dataGen = getDataGenerate()@@@3@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
1 [style = filled, label = "query.awaitTermination(streamingDurationInMs)@@@6@@@['1', '1', '0']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB1BBB"];
24 [style = filled, label = "List<String> records1 = recordsToStrings(recordsSoFar)@@@7@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
16 [style = filled, label = "String commitInstantTime1 = HoodieDataSourceHelpers.latestCommit(fs,tablePath)@@@13@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
0 [style = filled, label = "stream['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
5 [style = filled, label = "Dataset<Row> streamingInput@@@2@@@['1', '0', '0']", fillcolor = tomato, shape = box image = "AAA0AAABBB1BBB"];
12 [style = filled, label = "FileSystem fs = FileSystem.get(jssc.hadoopConfiguration())@@@12@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
0->3 [style = bold, label=""];
24->22 [style = solid, label="records1"];
8->6 [style = solid, label="writer"];
0->5 [style = dotted, label="true"];
21->19 [style = bold, label=""];
19->12 [style = bold, label=""];
9->11 [style = dotted, label="true"];
23->15 [style = bold, label=""];
3->6 [style = bold, label=""];
8->6 [style = bold, label=""];
12->16 [style = bold, label=""];
9->8 [style = bold, label=""];
24->22 [style = bold, label=""];
15->18 [style = bold, label=""];
16->14 [style = solid, label="commitInstantTime1"];
6->4 [style = bold, label=""];
25->20 [style = bold, label=""];
13->21 [style = solid, label="writer"];
12->16 [style = solid, label="fs"];
3->6 [style = solid, label="writer"];
20->24 [style = solid, label="recordsSoFar"];
18->25 [style = bold, label=""];
3->8 [style = dashed, label="0"];
16->14 [style = bold, label=""];
25->20 [style = solid, label="instantTime"];
4->1 [style = bold, label=""];
0->2 [style = dotted, label="true"];
9->7 [style = dotted, label="true"];
20->24 [style = bold, label=""];
13->21 [style = bold, label=""];
9->10 [style = dotted, label="true"];
23->17 [style = dotted, label="true"];
22->13 [style = bold, label=""];
0->7 [style = dotted, label="true"];
}
