digraph {
31 [style = filled, label = "filters.put(\"snowball\",null)@@@53@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
84 [style = filled, label = "tokenizers.put(\"nGram\",null)@@@7@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
44 [style = filled, label = "filters.put(\"limit\",null)@@@36@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
45 [style = filled, label = "filters.put(\"asciifolding\",null)@@@7@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
34 [style = filled, label = "filters.put(\"multiplexer\",null)@@@39@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
30 [style = filled, label = "filters.put(\"kstem\",null)@@@34@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
50 [style = filled, label = "filters.put(\"pattern_replace\",requiresAnalysisSettings(null))@@@43@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
7 [style = filled, label = "filters.put(\"indic_normalization\",null)@@@30@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
27 [style = filled, label = "filters.put(\"elision\",null)@@@22@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
23 [style = filled, label = "filters.put(\"delimited_payload_filter\",null)@@@17@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
41 [style = filled, label = "filters.put(\"brazilian_stem\",null)@@@9@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
47 [style = filled, label = "filters.put(\"apostrophe\",null)@@@4@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
61 [style = filled, label = "filters.put(\"hindi_normalization\",null)@@@28@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
22 [style = filled, label = "filters.put(\"cjk_width\",null)@@@11@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
1 [style = filled, label = "filters.put(\"delimited_payload\",null)@@@17@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
68 [style = filled, label = "tokenizers.put(\"lowercase\",null)@@@14@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
52 [style = filled, label = "filters.put(\"stemmer\",null)@@@56@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
43 [style = filled, label = "filters.put(\"length\",null)@@@35@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
85 [style = filled, label = "getTokenizers['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
81 [style = filled, label = "tokenizers.put(\"simple_pattern\",null)@@@4@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
10 [style = filled, label = "filters.put(\"pattern_capture\",requiresAnalysisSettings(null))@@@42@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
4 [style = filled, label = "filters.put(\"scandinavian_normalization\",null)@@@51@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
62 [style = filled, label = "filters.put(\"uppercase\",null)@@@62@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
82 [style = filled, label = "tokenizers.put(\"letter\",null)@@@13@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
63 [style = filled, label = "filters.put(\"dictionary_decompounder\",requiresAnalysisSettings(null))@@@18@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
78 [style = filled, label = "tokenizers.put(\"keyword\",null)@@@20@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
42 [style = filled, label = "filters.put(\"ngram\",null)@@@40@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
75 [style = filled, label = "tokenizers.put(\"edge_ngram\",null)@@@10@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
25 [style = filled, label = "filters.put(\"trim\",null)@@@59@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
54 [style = filled, label = "filters.put(\"unique\",null)@@@61@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
13 [style = filled, label = "filters.put(\"edge_ngram\",null)@@@20@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
24 [style = filled, label = "filters.put(\"synonym_graph\",requiresAnalysisSettings(null))@@@58@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
3 [style = filled, label = "filters.put(\"synonym\",requiresAnalysisSettings(null))@@@57@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
59 [style = filled, label = "filters.put(\"bengali_normalization\",null)@@@8@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
40 [style = filled, label = "filters.put(\"predicate_token_filter\",requiresAnalysisSettings(null))@@@46@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
70 [style = filled, label = "tokenizers.put(\"edgeNGram\",null)@@@9@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
26 [style = filled, label = "filters.put(\"classic\",null)@@@12@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
15 [style = filled, label = "filters.put(\"keep\",requiresAnalysisSettings(null))@@@31@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
2 [style = filled, label = "filters.put(\"edgeNGram\",null)@@@21@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
28 [style = filled, label = "filters.put(\"flatten_graph\",null)@@@24@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
71 [style = filled, label = "tokenizers.put(\"thai\",null)@@@6@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
74 [style = filled, label = "tokenizers.put(\"simple_pattern_split\",null)@@@5@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
48 [style = filled, label = "filters.put(\"remove_duplicates\",null)@@@47@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
17 [style = filled, label = "filters.put(\"lowercase\",null)@@@37@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
19 [style = filled, label = "filters.put(\"word_delimiter\",null)@@@64@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
18 [style = filled, label = "filters.put(\"porter_stem\",null)@@@45@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
56 [style = filled, label = "filters.put(\"scandinavian_folding\",null)@@@50@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
39 [style = filled, label = "filters.put(\"persian_normalization\",null)@@@44@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
49 [style = filled, label = "filters.put(\"cjk_bigram\",null)@@@10@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
35 [style = filled, label = "Map<String,AnalysisProvider<TokenFilterFactory>> filters = new TreeMap<>()@@@3@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
6 [style = filled, label = "filters.put(\"word_delimiter_graph\",null)@@@63@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
37 [style = filled, label = "filters.put(\"stemmer_override\",requiresAnalysisSettings(null))@@@55@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
57 [style = filled, label = "filters.put(\"russian_stem\",null)@@@49@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
55 [style = filled, label = "filters.put(\"czech_stem\",null)@@@13@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
16 [style = filled, label = "filters.put(\"dutch_stem\",null)@@@19@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
72 [style = filled, label = "Map<String,AnalysisProvider<TokenizerFactory>> tokenizers = new TreeMap<>()@@@3@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
21 [style = filled, label = "filters.put(\"arabic_stem\",null)@@@6@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
77 [style = filled, label = "tokenizers.put(\"uax_url_email\",null)@@@18@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
38 [style = filled, label = "getTokenFilters['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
32 [style = filled, label = "filters.put(\"keyword_marker\",requiresAnalysisSettings(null))@@@33@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
66 [style = filled, label = "tokenizers.put(\"path_hierarchy\",null)@@@15@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
5 [style = filled, label = "filters.put(\"truncate\",requiresAnalysisSettings(null))@@@60@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
9 [style = filled, label = "filters.put(\"keep_types\",requiresAnalysisSettings(null))@@@32@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
29 [style = filled, label = "filters.put(\"reverse\",null)@@@48@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
36 [style = filled, label = "filters.put(\"german_stem\",null)@@@27@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
20 [style = filled, label = "filters.put(\"decimal_digit\",null)@@@16@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
12 [style = filled, label = "filters.put(\"nGram\",null)@@@41@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
14 [style = filled, label = "filters.put(\"german_normalization\",null)@@@26@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
58 [style = filled, label = "filters.put(\"fingerprint\",null)@@@23@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
51 [style = filled, label = "return filters@@@65@@@['1', '1', '0']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB1BBB"];
0 [style = filled, label = "filters.put(\"common_grams\",requiresAnalysisSettings(null))@@@14@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
33 [style = filled, label = "filters.put(\"condition\",requiresAnalysisSettings(null))@@@15@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
67 [style = filled, label = "tokenizers.put(\"classic\",null)@@@12@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
11 [style = filled, label = "filters.put(\"sorani_normalization\",null)@@@54@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
8 [style = filled, label = "filters.put(\"serbian_normalization\",null)@@@52@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
65 [style = filled, label = "getTokenFilters['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
73 [style = filled, label = "tokenizers.put(\"ngram\",null)@@@8@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
46 [style = filled, label = "filters.put(\"french_stem\",null)@@@25@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
60 [style = filled, label = "filters.put(\"min_hash\",null)@@@38@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
76 [style = filled, label = "return tokenizers@@@21@@@['0', '0', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB3BBB"];
69 [style = filled, label = "tokenizers.put(\"pattern\",null)@@@17@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
64 [style = filled, label = "filters.put(\"arabic_normalization\",null)@@@5@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
79 [style = filled, label = "tokenizers.put(\"char_group\",null)@@@11@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
80 [style = filled, label = "tokenizers.put(\"PathHierarchy\",null)@@@16@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
53 [style = filled, label = "filters.put(\"hyphenation_decompounder\",requiresAnalysisSettings(null))@@@29@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
83 [style = filled, label = "tokenizers.put(\"whitespace\",null)@@@19@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
58->28 [style = bold, label=""];
64->21 [style = bold, label=""];
3->24 [style = bold, label=""];
48->29 [style = bold, label=""];
68->66 [style = bold, label=""];
27->58 [style = bold, label=""];
1->77 [style = dashed, label="0"];
49->22 [style = bold, label=""];
22->79 [style = dashed, label="0"];
39->18 [style = bold, label=""];
62->6 [style = bold, label=""];
35->72 [style = dashed, label="0"];
12->10 [style = bold, label=""];
45->84 [style = dashed, label="0"];
82->68 [style = bold, label=""];
16->78 [style = dashed, label="0"];
83->78 [style = bold, label=""];
66->80 [style = bold, label=""];
4->8 [style = bold, label=""];
43->44 [style = bold, label=""];
10->50 [style = bold, label=""];
47->64 [style = bold, label=""];
55->82 [style = dashed, label="0"];
9->32 [style = bold, label=""];
45->59 [style = bold, label=""];
11->37 [style = bold, label=""];
54->62 [style = bold, label=""];
41->49 [style = bold, label=""];
34->42 [style = bold, label=""];
67->82 [style = bold, label=""];
69->77 [style = bold, label=""];
44->17 [style = bold, label=""];
50->39 [style = bold, label=""];
31->11 [style = bold, label=""];
21->71 [style = dashed, label="0"];
21->45 [style = bold, label=""];
20->23 [style = bold, label=""];
15->9 [style = bold, label=""];
70->75 [style = bold, label=""];
26->67 [style = dashed, label="0"];
71->84 [style = bold, label=""];
2->27 [style = bold, label=""];
46->14 [style = bold, label=""];
47->81 [style = dashed, label="0"];
64->74 [style = dashed, label="0"];
75->79 [style = bold, label=""];
63->16 [style = bold, label=""];
38->35 [style = bold, label=""];
1->63 [style = bold, label=""];
29->57 [style = bold, label=""];
35->51 [style = solid, label="filters"];
14->36 [style = bold, label=""];
20->80 [style = dashed, label="0"];
22->26 [style = bold, label=""];
16->13 [style = bold, label=""];
8->31 [style = bold, label=""];
30->43 [style = bold, label=""];
18->40 [style = bold, label=""];
17->60 [style = bold, label=""];
65->35 [style = bold, label=""];
84->73 [style = bold, label=""];
20->1 [style = bold, label=""];
73->70 [style = bold, label=""];
32->30 [style = bold, label=""];
26->55 [style = bold, label=""];
72->81 [style = bold, label=""];
41->70 [style = dashed, label="0"];
24->25 [style = bold, label=""];
59->73 [style = dashed, label="0"];
81->74 [style = bold, label=""];
77->83 [style = bold, label=""];
7->15 [style = bold, label=""];
25->5 [style = bold, label=""];
79->67 [style = bold, label=""];
37->52 [style = bold, label=""];
19->51 [style = bold, label=""];
13->2 [style = bold, label=""];
5->54 [style = bold, label=""];
33->20 [style = bold, label=""];
40->48 [style = bold, label=""];
85->72 [style = bold, label=""];
74->71 [style = bold, label=""];
55->0 [style = bold, label=""];
42->12 [style = bold, label=""];
6->19 [style = bold, label=""];
57->56 [style = bold, label=""];
28->46 [style = bold, label=""];
61->53 [style = bold, label=""];
56->4 [style = bold, label=""];
53->7 [style = bold, label=""];
0->33 [style = bold, label=""];
60->34 [style = bold, label=""];
72->76 [style = solid, label="tokenizers"];
35->47 [style = bold, label=""];
23->1 [style = bold, label=""];
80->69 [style = bold, label=""];
49->75 [style = dashed, label="0"];
36->61 [style = bold, label=""];
52->3 [style = bold, label=""];
78->76 [style = bold, label=""];
59->41 [style = bold, label=""];
}
