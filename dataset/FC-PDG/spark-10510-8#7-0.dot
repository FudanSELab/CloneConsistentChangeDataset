digraph {
5 [style = filled, label = "Tokenizer tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")@@@7@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
2 [style = filled, label = "main['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
16 [style = filled, label = "sc.stop()@@@25@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
25 [style = filled, label = "SparkConf conf = new SparkConf().setAppName(\"JavaPipelineExample\")@@@3@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
31 [style = filled, label = "Dataset<Row> training = sqlContext.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0)),)@@@6@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
9 [style = filled, label = "SQLContext sqlContext = new SQLContext(sc)@@@5@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
6 [style = filled, label = "Dataset<Row> training = sqlContext.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0),new JavaLabeledDocument(4L,\"b spark who\",1.0),new JavaLabeledDocument(5L,\"g d a y\",0.0),new JavaLabeledDocument(6L,\"spark fly\",1.0),new JavaLabeledDocument(7L,\"was mapreduce\",0.0),new JavaLabeledDocument(8L,\"e spark program\",1.0),new JavaLabeledDocument(9L,\"a e c l\",0.0),new JavaLabeledDocument(10L,\"spark compile\",1.0),new JavaLabeledDocument(11L,\"hadoop software\",0.0)),)@@@6@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
17 [style = filled, label = "CrossValidator cv = new CrossValidator().setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator()).setEstimatorParamMaps(paramGrid).setNumFolds(2)@@@16@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
26 [style = filled, label = "PipelineModel model = pipeline.fit(training)@@@13@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
27 [style = filled, label = "Dataset<Row> test = sqlContext.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@14@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
20 [style = filled, label = "main['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
23 [style = filled, label = "SparkSession spark = SparkSession.builder().appName(\"JavaModelSelectionViaCrossValidationExample\").getOrCreate()@@@3@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
24 [style = filled, label = "Tokenizer tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")@@@5@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
8 [style = filled, label = "Dataset<Row> predictions = cvModel.transform(test)@@@19@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
29 [style = filled, label = "main['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
28 [style = filled, label = "sc.stop()@@@19@@@['0', '0', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB3BBB"];
11 [style = filled, label = "HashingTF hashingTF = new HashingTF().setNumFeatures(1000).setInputCol(tokenizer.getOutputCol()).setOutputCol(\"features\")@@@8@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
4 [style = filled, label = "SparkContext sc = new SparkContext(conf)@@@4@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
14 [style = filled, label = "spark.stop()@@@23@@@['1', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
19 [style = filled, label = "CrossValidatorModel cvModel = cv.fit(training)@@@17@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
7 [style = filled, label = "Dataset<Row> test = sqlContext.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@20@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
18 [style = filled, label = "HashingTF hashingTF = new HashingTF().setNumFeatures(1000).setInputCol(tokenizer.getOutputCol()).setOutputCol(\"features\")@@@6@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
10 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@21@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
32 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@17@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
1 [style = filled, label = "Dataset<Row> test = spark.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@18@@@['1', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
0 [style = filled, label = "SparkConf conf = new SparkConf().setAppName(\"JavaModelSelectionViaCrossValidationExample\")@@@3@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
15 [style = filled, label = "LogisticRegression lr = new LogisticRegression().setMaxIter(10).setRegParam(0.01)@@@9@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
21 [style = filled, label = "Dataset<Row> training = spark.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0),new JavaLabeledDocument(4L,\"b spark who\",1.0),new JavaLabeledDocument(5L,\"g d a y\",0.0),new JavaLabeledDocument(6L,\"spark fly\",1.0),new JavaLabeledDocument(7L,\"was mapreduce\",0.0),new JavaLabeledDocument(8L,\"e spark program\",1.0),new JavaLabeledDocument(9L,\"a e c l\",0.0),new JavaLabeledDocument(10L,\"spark compile\",1.0),new JavaLabeledDocument(11L,\"hadoop software\",0.0)),)@@@4@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
30 [style = filled, label = "Dataset<Row> predictions = model.transform(test)@@@15@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
12 [style = filled, label = "String(( args@@@2@@@['1', '1', '1']", fillcolor = tomato, shape = box image = "AAA0AAABBB1BBB"];
3 [style = filled, label = "ParamMap(( paramGrid = new ParamGridBuilder().addGrid(hashingTF.numFeatures(),new int((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78b98).addGrid(lr.regParam(),new double((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78ba2).build()@@@13@@@['1', '0', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
13 [style = filled, label = "Pipeline pipeline = new Pipeline().setStages(new PipelineStage((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78d9a)@@@10@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
22 [style = filled, label = "ParamMap(( paramGrid = new ParamGridBuilder().addGrid(hashingTF.numFeatures(),new int((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78cb1).addGrid(lr.regParam(),new double((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a78cbb).build()@@@11@@@['0', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB2BBB"];
14->16 [style = bold, label=""];
4->9 [style = bold, label=""];
8->10 [style = bold, label=""];
5->13 [style = solid, label="tokenizer"];
7->10 [style = solid, label="test"];
15->13 [style = bold, label=""];
11->13 [style = solid, label="hashingTF"];
1->8 [style = bold, label=""];
3->1 [style = bold, label=""];
10->14 [style = bold, label=""];
7->10 [style = bold, label=""];
7->1 [style = dashed, label="0"];
9->31 [style = bold, label=""];
0->23 [style = dashed, label="0"];
31->5 [style = bold, label=""];
27->30 [style = bold, label=""];
25->4 [style = bold, label=""];
29->25 [style = bold, label=""];
21->19 [style = solid, label="training"];
30->32 [style = bold, label=""];
6->31 [style = dashed, label="0"];
21->24 [style = bold, label=""];
29->12 [style = dotted, label="true"];
1->8 [style = solid, label="test"];
24->18 [style = bold, label=""];
17->19 [style = bold, label=""];
11->15 [style = bold, label=""];
8->7 [style = bold, label=""];
9->6 [style = bold, label=""];
25->4 [style = solid, label="conf"];
5->11 [style = solid, label="lr"];
6->5 [style = bold, label=""];
19->1 [style = bold, label=""];
26->27 [style = bold, label=""];
2->0 [style = bold, label=""];
10->30 [style = dashed, label="0"];
18->11 [style = solid, label="hashingTF"];
20->23 [style = bold, label=""];
13->3 [style = bold, label=""];
23->21 [style = bold, label=""];
0->25 [style = dashed, label="0"];
6->8 [style = solid, label="training"];
24->11 [style = solid, label="tokenizer"];
0->4 [style = bold, label=""];
13->26 [style = bold, label=""];
18->5 [style = bold, label=""];
16->14 [style = dashed, label="0"];
27->30 [style = solid, label="test"];
11->22 [style = bold, label=""];
2->12 [style = dotted, label="true"];
22->17 [style = bold, label=""];
15->13 [style = solid, label="lr"];
4->9 [style = solid, label="sc"];
5->11 [style = bold, label=""];
20->12 [style = dotted, label="true"];
0->4 [style = solid, label="conf"];
31->26 [style = solid, label="training"];
32->28 [style = bold, label=""];
}
