digraph {
0 [style = filled, label = "SparkSession spark = SparkSession.builder().appName(\"JavaPipelineExample\").getOrCreate()@@@3@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
11 [style = filled, label = "HashingTF hashingTF = new HashingTF().setNumFeatures(1000).setInputCol(tokenizer.getOutputCol()).setOutputCol(\"features\")@@@6@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
1 [style = filled, label = "spark.stop()@@@17@@@['1', '1', '0']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB1BBB"];
19 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@21@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
14 [style = filled, label = "LogisticRegression lr = new LogisticRegression().setMaxIter(10).setRegParam(0.001)@@@7@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
7 [style = filled, label = "PipelineModel model = pipeline.fit(training)@@@11@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
3 [style = filled, label = "Dataset<Row> predictions = model.transform(test)@@@13@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
16 [style = filled, label = "main['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
21 [style = filled, label = "Dataset<Row> training = spark.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0),new JavaLabeledDocument(4L,\"b spark who\",1.0),new JavaLabeledDocument(5L,\"g d a y\",0.0),new JavaLabeledDocument(6L,\"spark fly\",1.0),new JavaLabeledDocument(7L,\"was mapreduce\",0.0),new JavaLabeledDocument(8L,\"e spark program\",1.0),new JavaLabeledDocument(9L,\"a e c l\",0.0),new JavaLabeledDocument(10L,\"spark compile\",1.0),new JavaLabeledDocument(11L,\"hadoop software\",0.0)),)@@@4@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
25 [style = filled, label = "Dataset<Row> test = spark.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@18@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
24 [style = filled, label = "CrossValidatorModel cvModel = cv.fit(training)@@@17@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
5 [style = filled, label = "Pipeline pipeline = new Pipeline().setStages(new PipelineStage((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a79005)@@@8@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
18 [style = filled, label = "SparkSession spark = SparkSession.builder().appName(\"JavaModelSelectionViaCrossValidationExample\").getOrCreate()@@@3@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
8 [style = filled, label = "Dataset<Row> test = spark.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"mapreduce spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@12@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
6 [style = filled, label = "main['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
15 [style = filled, label = "Dataset<Row> test = spark.createDataFrame(Arrays.asList(new JavaDocument(4L,\"spark i j k\"),new JavaDocument(5L,\"l m n\"),new JavaDocument(6L,\"spark hadoop spark\"),new JavaDocument(7L,\"apache hadoop\")),)@@@12@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
4 [style = filled, label = "LogisticRegression lr = new LogisticRegression().setMaxIter(10).setRegParam(0.01)@@@7@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
22 [style = filled, label = "spark.stop()@@@23@@@['0', '0', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB3BBB"];
23 [style = filled, label = "Dataset<Row> predictions = cvModel.transform(test)@@@19@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
17 [style = filled, label = "CrossValidator cv = new CrossValidator().setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator()).setEstimatorParamMaps(paramGrid).setNumFolds(2)@@@16@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
9 [style = filled, label = "Dataset<Row> training = spark.createDataFrame(Arrays.asList(new JavaLabeledDocument(0L,\"a b c d e spark\",1.0),new JavaLabeledDocument(1L,\"b d\",0.0),new JavaLabeledDocument(2L,\"spark f g h\",1.0),new JavaLabeledDocument(3L,\"hadoop mapreduce\",0.0)),)@@@4@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
13 [style = filled, label = "main['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
20 [style = filled, label = "ParamMap(( paramGrid = new ParamGridBuilder().addGrid(hashingTF.numFeatures(),new int((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a79018).addGrid(lr.regParam(),new double((((edu.fdu.CPPDG.tinypdg.pe.ExpressionInfo@1a79022).build()@@@11@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
2 [style = filled, label = "System.out.println(\"(\" + r.get(0) + \", \" + r.get(1) + \") - prob=\" + r.get(2) + \", prediction=\" + r.get(3))@@@15@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
12 [style = filled, label = "String(( args@@@2@@@['1', '1', '1']", fillcolor = tomato, shape = box image = "AAA0AAABBB1BBB"];
10 [style = filled, label = "Tokenizer tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")@@@5@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
21->10 [style = bold, label=""];
0->9 [style = bold, label=""];
20->17 [style = bold, label=""];
16->18 [style = bold, label=""];
16->12 [style = dotted, label="true"];
5->20 [style = bold, label=""];
11->14 [style = bold, label=""];
13->12 [style = dotted, label="true"];
25->23 [style = bold, label=""];
2->1 [style = bold, label=""];
8->15 [style = dashed, label="0"];
11->4 [style = bold, label=""];
8->3 [style = bold, label=""];
6->0 [style = bold, label=""];
11->5 [style = solid, label="hashingTF"];
9->10 [style = bold, label=""];
14->5 [style = solid, label="lr"];
21->24 [style = solid, label="training"];
7->8 [style = bold, label=""];
15->3 [style = bold, label=""];
3->23 [style = dashed, label="0"];
8->3 [style = solid, label="test"];
10->5 [style = solid, label="tokenizer"];
17->24 [style = bold, label=""];
3->2 [style = bold, label=""];
9->7 [style = solid, label="training"];
9->21 [style = dashed, label="0"];
24->25 [style = bold, label=""];
23->19 [style = bold, label=""];
15->3 [style = solid, label="test"];
5->7 [style = bold, label=""];
7->15 [style = bold, label=""];
25->23 [style = solid, label="test"];
4->14 [style = dashed, label="0"];
0->18 [style = dashed, label="0"];
6->12 [style = dotted, label="true"];
18->21 [style = bold, label=""];
19->22 [style = bold, label=""];
4->5 [style = bold, label=""];
4->5 [style = solid, label="lr"];
13->0 [style = bold, label=""];
14->5 [style = bold, label=""];
10->11 [style = bold, label=""];
}
