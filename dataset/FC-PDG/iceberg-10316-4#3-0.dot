digraph {
35 [style = filled, label = "Assert.assertEquals(\"Number of snapshots should match\",2,Iterables.size(table.snapshots()))@@@29@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
5 [style = filled, label = "MemoryStream<Integer> inputStream = new MemoryStream<>(1,spark.sqlContext(),Encoders.INT())@@@11@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
25 [style = filled, label = "File lastCommitFile = new File(checkpoint.toString() + \"/commits/1\")@@@21@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
6 [style = filled, label = "PartitionSpec spec = PartitionSpec.builderFor(SCHEMA).identity(\"data\").build()@@@7@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
7 [style = filled, label = "File checkpoint = new File(parent,\"checkpoint\")@@@5@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
11 [style = filled, label = "inputStream.addData(JavaConversions.asScalaBuffer(batch1))@@@15@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
37 [style = filled, label = "File parent = temp.newFolder(\"parquet\")@@@3@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
17 [style = filled, label = "MemoryStream<Integer> inputStream = newMemoryStream(1,spark.sqlContext(),Encoders.INT())@@@10@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
18 [style = filled, label = "testStreamingWriteUpdateMode['0', '1', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB2BBB"];
23 [style = filled, label = "inputStream.addData(JavaConversions.asScalaBuffer(batch2))@@@18@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
27 [style = filled, label = "Assert.assertEquals(\"Result rows should match\",expected,actual)@@@28@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
31 [style = filled, label = "DataStreamWriter<Row> streamWriter = inputStream.toDF().selectExpr(\"value AS id\",\"CAST (value AS STRING) AS data\").writeStream().outputMode(\"append\").format(\"iceberg\").option(\"checkpointLocation\",checkpoint.toString()).option(\"path\",location.toString())@@@11@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
21 [style = filled, label = "restartedQuery.processAllAvailable()@@@24@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
22 [style = filled, label = "MemoryStream<Integer> inputStream = new MemoryStream<>(1,spark.sqlContext(),Encoders.INT())@@@10@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
10 [style = filled, label = "tables.create(SCHEMA,spec,location.toString())@@@9@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
16 [style = filled, label = "send(batch1,inputStream)@@@15@@@['0', '1', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB2BBB"];
32 [style = filled, label = "query.stop()@@@20@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
24 [style = filled, label = "{for (StreamingQuery query : spark.streams().active()){query.stop()}}@@@31@@@['0', '0', '1']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB3BBB"];
30 [style = filled, label = "StreamingQuery query = streamWriter.start()@@@13@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
13 [style = filled, label = "HadoopTables tables = new HadoopTables(CONF)@@@6@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
12 [style = filled, label = "List<Integer> batch2 = Lists.newArrayList(3,4)@@@17@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
8 [style = filled, label = "testStreamingWriteUpdateMode['1', '0', '0']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB1BBB"];
29 [style = filled, label = "query.processAllAvailable()@@@19@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
34 [style = filled, label = "Assert.assertEquals(\"Number of rows should match\",expected.size(),actual.size())@@@27@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
36 [style = filled, label = "File location = new File(parent,\"test-table\")@@@4@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
28 [style = filled, label = "testStreamingWriteAppendMode['0', '0', '1']", fillcolor = lightgray, shape = diamond image = "AAA0AAABBB3BBB"];
9 [style = filled, label = "DataStreamWriter<Row> streamWriter = inputStream.toDF().selectExpr(\"value AS id\",\"CAST (value AS STRING) AS data\").writeStream().outputMode(\"update\").format(\"iceberg\").option(\"checkpointLocation\",checkpoint.toString()).option(\"path\",location.toString())@@@11@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
3 [style = filled, label = "{for (StreamingQuery query : spark.streams().active()){query.stop()}}@@@18@@@['1', '1', '0']", fillcolor = lightgray, shape = ellipse image = "AAA0AAABBB1BBB"];
33 [style = filled, label = "StreamingQuery restartedQuery = streamWriter.start()@@@23@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
1 [style = filled, label = "List<Integer> batch1 = Lists.newArrayList(1,2)@@@14@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
2 [style = filled, label = "exceptionRule.expectMessage(\"Output mode Update is not supported\")@@@4@@@['1', '0', '0']", fillcolor = red, shape = ellipse image = "AAA1AAABBB1BBB"];
0 [style = filled, label = "query.processAllAvailable()@@@16@@@['1', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
20 [style = filled, label = "Assert.assertTrue(\"The commit file must be deleted\",lastCommitFile.delete())@@@22@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
15 [style = filled, label = "Table table = tables.create(SCHEMA,spec,location.toString())@@@8@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
19 [style = filled, label = "Dataset<Row> result = spark.read().format(\"iceberg\").load(location.toString())@@@25@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
26 [style = filled, label = "List<SimpleRecord> actual = result.orderBy(\"id\").as(Encoders.bean()).collectAsList()@@@26@@@['0', '0', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB3BBB"];
4 [style = filled, label = "exceptionRule.expect()@@@3@@@['1', '1', '0']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
14 [style = filled, label = "List<SimpleRecord> expected = Lists.newArrayList(new SimpleRecord(1,\"1\"),new SimpleRecord(2,\"2\"),new SimpleRecord(3,\"3\"),new SimpleRecord(4,\"4\"))@@@9@@@['1', '1', '1']", fillcolor = white, shape = ellipse image = "AAA0AAABBB1BBB"];
7->13 [style = bold, label=""];
7->13 [style = solid, label="parent"];
11->16 [style = bold, label=""];
37->36 [style = solid, label="parent"];
12->23 [style = solid, label="batch2"];
10->15 [style = dashed, label="0"];
28->37 [style = bold, label=""];
30->1 [style = bold, label=""];
37->36 [style = bold, label=""];
15->14 [style = bold, label=""];
5->9 [style = bold, label=""];
21->19 [style = bold, label=""];
17->16 [style = solid, label="inputStream"];
17->9 [style = bold, label=""];
0->12 [style = bold, label=""];
26->34 [style = bold, label=""];
0->16 [style = dashed, label="0"];
14->22 [style = bold, label=""];
22->31 [style = bold, label=""];
14->10 [style = bold, label=""];
10->17 [style = bold, label=""];
14->10 [style = solid, label="spec"];
4->2 [style = bold, label=""];
7->6 [style = solid, label="parent"];
6->15 [style = solid, label="spec"];
4->7 [style = bold, label=""];
6->15 [style = bold, label=""];
20->33 [style = bold, label=""];
1->11 [style = bold, label=""];
27->35 [style = bold, label=""];
35->24 [style = bold, label=""];
11->16 [style = solid, label="batch1"];
23->29 [style = bold, label=""];
25->20 [style = bold, label=""];
11->0 [style = bold, label=""];
26->27 [style = solid, label="actual"];
10->5 [style = bold, label=""];
18->4 [style = bold, label=""];
5->17 [style = dashed, label="0"];
9->31 [style = dashed, label="0"];
36->7 [style = bold, label=""];
14->27 [style = solid, label="expected"];
19->26 [style = bold, label=""];
29->32 [style = bold, label=""];
31->30 [style = bold, label=""];
32->25 [style = bold, label=""];
12->23 [style = bold, label=""];
12->3 [style = bold, label=""];
37->7 [style = solid, label="parent"];
2->7 [style = bold, label=""];
13->6 [style = bold, label=""];
8->4 [style = bold, label=""];
9->1 [style = bold, label=""];
33->21 [style = bold, label=""];
11->0 [style = solid, label="batch1"];
16->12 [style = bold, label=""];
1->11 [style = solid, label="batch1"];
34->27 [style = bold, label=""];
}
